\section{Defaults for functions}
Default values for all function and operator attributes are stored in the \ \texttt{FunctionDefaults} class. This is
actually a template so that different values can be set for functions with different numbers of dimensions. We saw
above that

{\ttfamily
FunctionDefaults{\textless}1{\textgreater}::set\_cubic\_cell(0,10);}

sets the user's simulation cell as  $[0,10]$. Presently, all functions of a given dimension must share the same cell.
Two other common attributes are

\begin{itemize}
\item \texttt{k} -- the wavelet order. A practical rule of thumb is if the default truncation threshold is  $10^{-n}$
that the order be chosen as  $k=n+2$. The default is 6.
\item \texttt{thresh} -- the truncation threshold. The default is 1e-4.
\item \texttt{bc} -- the boundary conditions. See below for more details. The default is free.
\end{itemize}
\section{Boundary conditions}
In MADNESS, boundary conditions are associated with operators not functions and the boundary conditions are imposed on
the surface enclosing the entire simulation volume. I.e., they are exterior boundary conditions. For derivative
operators the following conditions are understood, and can be imposed separately on each surface

\begin{itemize}
\item \texttt{BC\_ZERO} -- Zero Dirichlet
\item \texttt{BC\_PERIODIC} -- Periodic (both left and right surfaces must agree on this value)
\item \texttt{BC\_FREE }{}-- Free (default)
\item \texttt{BC\_DIRICHLET} -- General Dirichlet (requires provision of one or more functions)
\item \texttt{BC\_ZERONEUMANN }{}-- Zero Neumann
\item \texttt{BC\_NEUMANN} -- General Neumann (requires provision of one or more functions)
\end{itemize}
For integral operators only periodic and free-space conditions are understood -- BC\_PERIODIC yields periodic and all
other conditions yield free-space.

Example: to make the default boundary conditions in 3D

{\ttfamily
BoundaryConditions{\textless}3{\textgreater} bc(BC\_FREE);}

Example: to make boundary conditions in 3D with zero Dirichlet in x and y and periodic in z,

{\ttfamily
BoundaryConditions{\textless}3{\textgreater} bc(BC\_ZERO);}

{\ttfamily
bc(2,0) = bc(2,1) = BC\_PERIODIC}

Example: to override the default boundary conditions with yours in a variable named \texttt{bc} in 3D

{\ttfamily
FunctionDefaults{\textless}3{\textgreater}::set\_bc(bc);}

\section{Differentiation, multiplication, inner products -- e.g., energy of the hydrogen atom}
In this section we examine operations such as differentiation, inner product and multiplication. A relevant simple
example is \texttt{hatom\_energy.cc}.

\subsection{Differentiation}
Differentiation is performed by applying a differential operator to a function. The operator is constructed with desired
the boundary conditions and direction for differentiation (directions are indexed starting from zero, so in 3D
\texttt{x=0}, \texttt{y=1} and \texttt{z=2}). The operators can be kept for repeated application, or made and discarded
after use.

For example, to make the derivative operator in 3D with respect to the first variable using boundary conditions from
\texttt{FunctionDefaults}, and to apply it to functions \texttt{f}, \texttt{g} and \texttt{h}.

\begin{quote}
\begin{verbatim}
real_derivative_3d Dx(world, 0); 
real_function_3d dfdx = Dx(f); 
real_function_3d dgdx = Dx(g); 
real_function_3d dhdx = Dx(h); 
\end{verbatim}
\end{quote}

\subsection{Multiplication, addition, subtraction of functions}
Most simple mathematical operations can be composed in MADNESS as they are normally written in standard notation. For
instance, if \ \texttt{f}, \texttt{g} and \texttt{h} are functions the expression 

\begin{equation}
f(x)=2g(x)+3h(x)-7g(x)h(x)+99
\end{equation}
is transcribed as

{\ttfamily
f = 2*g + 3*h - 7*g*h + 99}

where \texttt{*} indicates point-wise multiplication of functions.

\textit{Important: }Addition and subtraction of functions are exact operations in the sense that the result can be
exactly represented in MADNESS basis. Multiplication is \textit{inexact} since the product of two polynomials of order 
$k$ is of order  $2k$. The auto-refinement algorithm within MADNESS is still under development -- please refer to the
implementation notes for more detail.

\subsection{Inner products}
The inner product of two functions is defined as 
\begin{equation}
\left( f \left| g \right. \right) - \int f(x)^\textrm{*} g(x) dx
\end{equation}
where  $\textrm{*}$ indicates complex conjugation and the integral is taken over the entire simulation volume. The above
is computed for two MADNESS functions \texttt{f} and \texttt{g} of the same type using

{\ttfamily
inner(f,g)}

If the input functions are real, the result is real; for complex functions the result is complex.

\section{Integral operators -- e.g., solution of Laplace or Poisson's equations}
The Poisson equation
\begin{equation}
\nabla ^{2}u=-4\pi \rho 
\end{equation}
is ubiquitous in scientific and engineering simulations. \ For the sake of simplicity, we assume free-space boundary
condition (zero at infinity, so the Green's function is just  $1/\left|r\right|$). \ \ If the right hand side of the
Poisson equation is \texttt{rho} then the Poisson equation can be solved as

{\ttfamily
real\_convolution\_3d op=CoulombOperator(world, 0.001, 1e-6);}

{\ttfamily
real\_function\_3d result = op(rho);}

This is employed in many example codes in the examples directory. The call to the Coulomb operator builds a
low-separation rank approximation (see the implementation notes) of the Green function for the Poisson equation. \ The
approximation is accurate to 1e-6 from a smallest length scale of 0.001 to the entire box size.

If you have more complicated boundary conditions which require single or double layer terms please refer the examples in
\texttt{interior\_dirichlet.cc} or \texttt{laplace\_sphere.cc} for more details.

\section{Operations on vectors of functions -- e.g., calculating multiple eigenfunctions}
The header file \texttt{vmra.h} defines operations on vectors of functions. These are convenient in eliminating
error-prone loops over arrays/vectors of functions, and the vector operations are much more efficient since many
operations can occur in parallel. The example code \texttt{vnucso.cc} and the molecular density function code make
extensive use of the vector API (application programming interface) to solve eigen-problems.

Given a subspace defined by a vector of  $n$ functions  $f_{i}(x)\ i=0,\ldots ,n-1$ we can diagonalize the operator 
$\hat{H}$ in the subspace by constructing the matrix representations of the operator ( $H$) and metric ( $S$)
\begin{align*}
h_{ij} & = \left< f_i \left| \hat{H} \right| f_j \right> \\
s_{ij} & = \left< f_i \left|         \right. f_j \right>
\end{align*}
and then solving the generalized eigenvalue problem 

\begin{equation}
HC=SCE
\end{equation}
to obtain the eigenvalues and coefficients in the subspace. The eigenfunctions  $u_{i}(x)$ are obtained by transforming
the original basis 

\begin{equation}
u=fC\ \ \ \mathrm{\text{or}}\ \ \ u_{i}(x)=\sum _{j}f_{j}(x)c_{ji}
\end{equation}

\bigskip

Given an STL vector of 3D functions \texttt{f} and another \texttt{Hf} containing result of applying the operator 
$\hat{H}$ to the vector, the above is compactly translated into MADNESS as

\begin{quote}
\begin{verbatim}
real_tensor H = matrix_inner(f,Hf); 
real_tensor S = matrix_inner(f,f); 
real_tensor C,E; 
sygv(H,S,1,C,E); 
vector_real_function_3d evec = transform(f,C); 
\end{verbatim}
\end{quote}

The \texttt{matrix\_inner()} routine computes the matrix of inner products (or matrix elements) of two vectors of
functions, and the \texttt{sygv()} routine (in \texttt{linalg/tensor\_lapack.h}) is a wrapper around the LAPACK real
symmetric and complex Hermitian generalized eigenvalue routines. Finally, the \texttt{transform()} routine transforms
the basis to compute the eigenfunctions.

\section{Moving functions to/from disk}
It takes at most a couple of lines of code to move a function to/from disk. \ The example program \texttt{functionio.cc}
shows how to do this, and the critical lines are
\begin{quote}
\begin{verbatim}
ParallelOutputArchive out(world, filename); 
out & f & g & h; 
ParallelInputArchive in(world, filename); 
in & f & g & h; 
\end{verbatim}
\end{quote}

Here, \texttt{f}, \texttt{g}, and \texttt{h} are MADNESS functions of any type (they need not have the same type or
dimension). 

MADNESS has a generic mechanism for (de)serializing objects from directional streams that it calls archives to avoid
confusion with the STL stream concept. \ \ \ Anything can be written to and read from a stream, though user-defined
types usually need a little additional code to enable this (see \texttt{world/archive.h} for documentation). Most
archives are sequential objects accessible only to a single process and it makes little sense to write a potentially
large function that is distributed across the entire parallel computer to such a stream. For that reason, functions
must be written to/from a parallel archive that performs efficient parallel I/O.

Large amounts of data (more than a few gigabytes) will benefit from increasing the number of processors actually doing
disk I/O (refer to the relevant parallel archive class for more info).

Note that the program \texttt{mraplot} can be used to generate plots from functions stored on disk.

\section{Plotting}
MADNESS can presently generate uniform grids in formats suitable for the visualization software OpenDX (in a
``\texttt{.dx}{}'' file) and Paraview (in a VTK file), and line plots in a text format suitable for nearly any tool
(e.g., \ gnuplot or xmgrace).

Note that the program \texttt{mraplot} can be used to generate plots from functions stored on disk.

\subsection{OpenDX}
OpenDX is an Open Source visualization software based on IBM's Visualization Data Explorer
(\href{http://www.opendx.org/}{www.opendx.org}). \ Please refere to the OpenDX manual on its use. \ \ An example
configuration file (\texttt{vizit.cfg}) \ and a network file (\texttt{vizit.net}) can be found in the
\texttt{trunk/src/apps/moldft} directory. \ Here are some details on creating your own DX files.

Given any MADNESS function \texttt{f}, you can write to disk a uniform grid over the entire simulation volume as follows

{\ttfamily
plotdx(f, ``f.dx'');}


\bigskip

Additional arguments permit us to change the plot volume (default is the entire simulation volume), the number of points
(default is 201) and binary/text format (default is binary). This is a collective operation.

Visualizing this with OpenDX is straightforward, but depends on the number of dimensions. The easiest way is to start
OpenDX, click ``Import Data ...'', enter your filename, click ``Visualize Data''. However, you will want to learn how
to build your own networks. To display an iso-surface of 3D data, start the visual editor and connect

{\ttfamily
file-selector -{}-{\textgreater} import -{}-{\textgreater} isosurface -{}-{\textgreater} image}

Enter your name in the file-selector, and you should be seeing a picture. You can adjust the isosurface value in the
isosurface control or by connecting it to an interactor. Have fun!

\subsection{Line plots}
With a single function call, up to three functions can be simultaneously evaluated at points along a line with the
values printed to a file suitable for use by any standard 2D graphics or spreadsheet software. E.g., to plot one 4D
function (\texttt{f}) along a line between (0,0,0,1) and (0,1,0,2) with 101 points

\begin{quote}
\begin{verbatim}
coord_3d lo,hi; 
lo[3]=1.0; hi[1]=1.0; hi[2]=2.0; 
plot_line(‘‘plot.txt’’, 101, lo, hi, f); 
\end{verbatim}
\end{quote}

To plot two functions (\texttt{f} and \texttt{g}) you would use instead

{\ttfamily
plot\_line(``plot.txt'', 101, lo, hi, f, g)}

With gnuplot, you can plot the data as follows

\begin{quote}
\begin{verbatim}
gnuplot -persist -e 'set style data lines; plot "plot.txt"'
\end{verbatim}
\end{quote}

\subsection{VTK format and Paraview}
MADNESS can export MADNESS functions to the serial vtkStructuredGrid (.vts) file format which can be ready by several
post-processing visualization packages such as Paraview. \ To write this data file, you must first define four
quantities: a filename (\textit{filename)}, the lower (\textit{plotlo}) and upper (\textit{plothi}) bound of the
Cartesian coordinates in each dimension to plot, and the number of points (\textit{npts)} in each dimension to
evaluate.

\textit{Note:}\textbf{ }At this time, MADNESS evaluates the functions at equally spaced points between \textit{plotlo
}and \textit{plothi}. \ 

After the above four quantities have been defined, three functions must be called:

\ \ \texttt{plotvtk\_begin }: Writes the VTK boilerplate header information

\ \ \texttt{plotvtk\_data} : Evaluates and writes the MADNESS function at \textit{npts}

\ \ \texttt{plotvtk\_end }: Writes the VTK boilerplate footer information


\bigskip

\textit{Note:}\textbf{ }Currently, the function evaluation in plotvtk\_data is done in serial. \ 

An example of code for plotting two two-dimensional functions \textit{u} and \textit{v} is as follows in a
[0,1]\textsuperscript{2} box with 101 points is as follows:

\begin{quote}
\begin{verbatim}
char filename[100]; 
sprintf(filename, output.vts); // Defines the filename 
Vector<double, 2> plotlo, plothi; // Box dimensions 
Vector<long, 2> npts; // Num points in each dim for(int 
i = 0; i < 2; ++i) 
{ 
	plotlo[i] = 0.0; 
	plothi[i] = 1.0; 
	npts[i] = 101; 
} 
plotvtk_begin(world, filename, plotlo, plothi, npts); 
plotvtk_data(u, u, world, filename, plotlo, plothi, npts); 
plotvtk_data(v, v, world, filename, plotlo, plothi, npts); 
plotvtk_end<3>(world, filename); 
\end{verbatim}
\end{quote}

\textit{Note: }An arbitrary number of MADNESS files may be written to a single file. \ Two are shown above for
demonstrative purposes; however, plotvtk\_data may be called multiple times between plotvtk\_begin and plotvtk\_end
function calls.

{\bfseries
\textmd{\textit{Note: }}\textmd{For time-dependent simulations, the above code can be included within the time step
loop. \ The user should then consider appending the filename with the timestep number and create Ntimestep files, each
containing one increment of time.}}

To visualize your functions, Paraview has been extensively tested, although other external visualization packages may
also be compatible with the vts file format. \ Paraview is an open-source visualization application that is freely
downloadable. \ For information about how to download, install and use Paraview, please consult their webpage at
http://www.paraview.org.

\section{Load and memory balancing}
Load and memory balancing is a critical issue on current generation of shared and distributed memory computers. \ On
many terascale and petascale computer there is no virtual memory capabilities on the compute nodes so memory management
is very important.

Poor distribution of work (load imbalance) is the largest reason for inefficient parallel execution within MADNESS.
\ Poor data distribution (data imbalance) contributes to load imbalance and also leads to out-of-memory problems due to
one or more processes having too much data. \ Thus, we are interested in uniform distribution of both work and data. 

Many operations in MADNESS are entirely data driven (i.e., computation occurs in the processor that
"owns" the data) since there is insufficient work to justify moving data between processes
\ (e.g., computing the inner product between functions). \ However, a few expensive operations can have work shipped to
other processors. 

There are presently three load balancing mechanisms within MADNESS 

\begin{itemize}
\item static and driven by the distribution of data, 
\item dynamic via random assignment of work, and 
\item dynamic via work stealing (currently only in prototype). 
\end{itemize}
Until the work stealing becomes production quality we must exploit the first two forms. \ The random work assignment is
controlled by options in the FunctionDefaults class. 

\begin{itemize}
\item \texttt{FunctionDefaults::set\_apply\_randomize(bool) }controls the use of randomization in applying integral
(convolution) operators. It is typically beneficial when computing to medium/high precision. 
\item \texttt{FunctionDefaults::set\_project\_randomize(bool)} controls the use of randomization in projecting from an
analytic form (i.e., C++) into the discontinuous spectral element basis. \ It is typically \ beneficial unless there is
already a good static data distribution. \ Since these options are straightforward to enable, this example focuses on
static data redistribution. 
\end{itemize}
The process map (an instance of \texttt{WorldDCPmapInterface}) controls mapping of data to processors and it is actually
quite easy to write your own (e.g., see \texttt{WorldDCDefaultPmap }\texttt{or LevelPmap}) that ensure uniform data
distribution. \ However, you also seek to incorporate estimates of the computational cost into the distribution. \ The
class \texttt{LBDeuxPmap} (deux since it is the second such class) in \texttt{trunk/src/lib/mra/lbdeux.h} does this by
examining the functions you request and using provided weights to estimate the computational cost. 

Communication costs are proportional to the number of broken links in the tree. \ Since some operations work in the
scaling function basis, some in the multiwavelet basis, and some in non-standard form, there is an element of
empiricism in getting best performance from most algorithms. 

The example code in \texttt{trunk/src/apps/examples/dataloadbal.cc} illustrates how the discussions in this section can
be applied.

\section{How to ``think'' MADNESS}
MADNESS is based on multiresolution analysis (MRA) and low-separation rank (LSR) approximations of functions and
operators. \ It can be considered an adaptive spectral elemen method using a discontinuous and singular multiresolution
basis. \ The representations of differential operators in the wavelet bases are provably similar to adaptive finite
difference discretizations. \ Thus, the process of solving the resulting linear systems will have similar behaviors as
in other adaptive methods. \ For example, the derivative operator and the Laplacian operator are unbounded operators.
\ Thus the condition number, which often constraints how accurately the linear system can be solved, goes to infinity
as the bases or the nets are refined. \ In order to solve these equations in practice, one has to precondition the
system. \ Effective preconditioners are problem dependent and the theory of their construction is an area of on-going
research.

The integral operator, which is the formal inverse associated to the differential operator, are usually bounded
operator. \ MRA and LSR have been proven to be one of the techniques that can effectively apply some of the physically
important operators and their kernel fast and with ease.

Two of the most important operators that we illustrate in this manual are the Poisson operator (in section 5), and the
\ Helmholtz operator. \ The heat equation is ...

\subsection{Solve the integral equation}
In many situations the integral operator associated to the differential operator have an analytic kernel. \ The simplest
examples are the convolution operators. \ In equation (9) the free-space Poisson equation is converted to a convolution
with the Poisson (or Coulomb) kernel, the Schrodinger equation with potential  $V$ is converted to a Lippman-Schwinger
equation using the bound-state Helmholtz kernel, and the last example applies Duhamel's principle to write a time
dependent differential equation with linear operator  $\hat{L}$ and a non-linear operator  $N$ as a semi-group
equation.


\begin{align*}\label{eqn:refText8}
\nabla ^{2}u=-4\pi \rho                     & \to u=G\ast \rho    \ \ \    \textrm{where} G(r-r')=\frac{1}{|r-r'|} \\
-{\frac{1}{2}}\nabla ^{2}\psi +V\psi =E\psi & \to \psi =-2G\ast V\psi \ \ \ \textrm{where} G(r-r')=\frac{e^{-\sqrt{-2E|r-r'|}}}{4\pi |r-r'|}\\
\hat{L}u+N(u,t)=\dot{u}                     & \to u(t)=e^{\hat{L}t}u(0) +\int _{0}^{t}e^{\hat{L}(t-t')}N(u,t')\mathit{dt}' &
\end{align*}

Most codes, including MADNESS, are bad at solving differential equations to high accuracy -- this is why there is so
much emphasis placed on finding a good pre-conditioner. The problem arises from the spectrum of the differential
operator. Consider the Laplacian in 1D acting on a plane wave 

\begin{equation}
\frac{d^{2}}{\mathit{dx}^{2}}e^{i\omega x}=-\omega ^{2}e^{i\omega x}
\end{equation}
The effect of the Laplacian is to greatly amplify high frequencies  $\omega $ (where most of the numerical error lies)
whereas physical applications are primarily interested in lower frequencies. The eigenvalues of the corresponding
inverse or integral operator have the opposite effect -- high frequencies are suppressed and lower frequencies
emphasized.

The integral form is potentially better in many ways -- accuracy, speed, robustness, asymptotic behavior, etc.. If you
really, really, want to solve the differential form, then instead of using the phrase ``integral form'' say ``perfectly
preconditioned differential form'' so that you can do the right thing.

\subsection{Carefully analyze discontinuities, noise, singularities, and asymptotic forms}
Your function needs to be evaluated at close to machine precision. \ The higher the order of the basis ( $k$) the
greater the necessary accuracy regardless of what threshold you are trying to compute to. \ The accuracy and
convergence of the Gauss-Legendre quadrature rests on the function being smooth (well approximated by a polynomial) at
some level of refinement. Discontinuities in the function value or derivatives, \ singularities, and numerical noise
can all cause excessive refinement as MADNESS tries to deliver the requested precision-Gibbs effect in action.
\textit{The usual symptoms of this problem are unexpectedly slow execution and excessive memory use.} Here are some
tips to work with these effects.

Discontinuities and singularities need to be consciously managed. Integrable point singularities might sometimes work
unmodified (e.g.,  $1/r$ in 3-D) but can unpredictably fail, e.g., if a quadrature point lands very near the
singularity by accident. If possible, arrange for such points/surfaces to coincide with dyadic points (i.e., an integer
multiple of some power of two division of the domain) -- this will give the most accurate representation and exploits
the discontinuous spectral basis. If you cannot ensure such placement, you must manually or analytically regularize the
function and one would usually employ a parameter to control the length scale of any problem modification and to enable
systematic demonstration of convergence. E.g., eliminate the cusp in an exponential with

\begin{equation}
\exp (-r)\to \exp (-\sqrt{r^{2}+\sigma ^{2}})
\end{equation}
or replace a step function with 

\begin{equation}
\theta (x)\to \theta (x,\lambda )=\frac{1}{2}(1+\tanh \frac{x}{\lambda })
\end{equation}
or the Coulomb potential in 3-D with 

\begin{equation}
\frac{1}{r}\to u(r,c)=\frac{1}{r}\operatorname{erf}\frac{r}{c}+\frac{1}{c\sqrt{\pi
}}e^{-\left(\frac{r}{c}\right)^{2}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \int _{0}^{\infty
}\left(u(r,c)-r^{-1}\right)r^{2}\mathit{dr}=0
\end{equation}
(the integral indicates that the mean error is zero independent of  $c$).

Numerical noise can be a problem if your function is evaluated using interpolation or some other approximation scheme,
or when switching between representations (e.g., between forms suitable for small or large arguments). If you are
observing inefficient projection into the basis, ensure that your approximation is everywhere smooth to circa 1 part in
 $10^{12}$ or better.

MADNESS itself computes to a finite precision and when computing a point-wise function of a function (i.e.,  $g(f(x))$
where  $f(x)$ is a MADNESS function and  $g(s)$ is a user-provided function) the user-provided function must tolerate
that approximation within tolerance or noise. A classic example is computing the function

\begin{equation}
V(\rho (x))=\frac{C}{\rho ^{1/3}(x)}
\end{equation}
where in the original problem one knows that  $\rho (x)>0,\ \forall x$ but numerically this positivity not guaranteed.
In this case an effective smoothing is 

\begin{equation}
\begin{gathered}V(\rho )\to V(S(\rho ))\\S(s)=\left\{\begin{matrix}s_{0}&s\le 0\\q(s,s_{0,}s_{1})&0<s\le
s_{1}\\s&s>s_{1}\end{matrix}\right.\\q(s,s_{0},s_{1})=s_{0}-(-2s_{1}+3s_{0})\left(\frac{s}{s_{1}}\right)^{2}+(2s_{0}-s_{1})\left(\frac{s}{s_{1}}\right)^{3}\end{gathered}
\end{equation}
The function  $S(s)$ coincides with its argument for  $s>s_{1}$ and for smaller values smoothly switches to a minimum
value of  $s_{0}$ with continuous value and derivative at both end points.

Some computations are intrinsically expensive. For instance, the function  $\exp (i\omega r)$ is oscillatory everywhere
and the number of required coefficients will increase linearly with the solution volume. \ In a 3-D box of width  $L$,
the number of coefficients will be  $O\left(\left(Lk\omega \right)^{3}\right)$ (where  $k$ is the multiwaveler or
polynomial order). For  $L=1000$,  $k=12$ and  $\omega =3$, a few hundred TB of data (i.e., too big!) will be
generated. Thus, it is worth making a back of the envelope estimate about the expected cost of computation before
getting started.

\subsection[Robustly trade precision for speed]{Robustly trade precision for speed}
TO BE COMPLETED.

\subsection{Choice of polynomial order (k)}
TO BE COMPLETED.

\section{Environment variables}
\texttt{MAD\_BIND} -- Specifies the binding of threads to physical processors. On both the Cray-XT and the IBM BG/P the
default value should be used. On other machines there is sometimes a small performance gain to be had from forcing
threads to use the same processor, thereby improving cache locality. The value is a character string containing three
integers in the range. The first indicates the core to which the main thread should be bound, the second the core for
the communication thread, and the third the core for first thread in the pool. Subsequent threads use successively
higher cores. A value of -1 indicates do not bind. The default on the XT is ``\texttt{1 0 2}{}'' and on the BG/P
``\texttt{{}-1 -1 -1}{}''.

\texttt{MAD\_NUM\_THREADS} -- Specifies the total number of threads to be used by each MPI process. If running with just
one MPI processes, there will be this many threads executing the application code so the minimum value is one. If
running with more than one MPI processes, one thread is dedicated to communication so the minimum value is two. The
default value is the number of processors detected (using this default is the only way presently to have different
numbers of threads on different nodes).

\texttt{MRA\_DATA\_DIR} -- Specifies the directory that contains the MADNESS data files (notably the autocorrelation
coefficients, two-scale coefficients, and Gauss-Legendre points and weights). Sometimes the compiled-in default must be
overridden. Only MPI process zero will use this.

\texttt{POOL\_NTHREAD} (deprecated) -- Specifies the number of threads in the compute pool. New users should set
\texttt{MAD\_NUM\_THREADS} instead.
